{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OVERVIEW\n",
    "# Data\n",
    "# What position each team drafted and what their stats for the previous season was\n",
    "# Chargers 2020 Draft QB, LB - Chargers 2019 receiving, rushing, tackles, ints, points for, etc\n",
    "    \n",
    "# 1st Round Draft History Data - http://www.drafthistory.com/index.php/rounds/round_1\n",
    "# Team Stats and Rankings - https://www.pro-football-reference.com/teams/cin/2019.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "# Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ML Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Web Scraping\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Math\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "# CONSTANTS\n",
    "CURRENT_YEAR = 2020\n",
    "YEARS = 20\n",
    "TEAM_DICT = {'Bengals':'cin','Redskins':'was','Lions':'det','Giants':'nyg','Dolphins':'mia','Chargers':'sdg',\n",
    "            'Panthers':'car','Cardinals':'crd','Jaguars':'jax','Browns':'cle','Jets':'nyj','Raiders':'rai',\n",
    "             'Buccaneers':'tam','49ers':'sfo','Broncos':'den','Falcons':'atl','Cowboys':'dal','Eagles':'phi',\n",
    "             'Vikings':'min','Saints':'nor','Packers':'gnb','Seahawks':'sea','Ravens':'rav','Titans':'oti',\n",
    "             'Chiefs':'kan','Colts':'clt','Texans':'htx','Bears':'chi','Steelers':'pit','Rams':'ram','Bills':'buf',\n",
    "             'Patriots':'nwe'}\n",
    "POS_DICT = {'QB':1,'RB':2,'WR':3,'TE':4,' C':5,' G':6,' T':7,'DT':8,'DE':9,'LB':10,'DB':11}\n",
    "EMPTY_COLS = ['Off. Rank Ply', 'Off. Rank Y/P', 'Off. Rank Cmp', 'Off. Rank 1stD', 'Off. Rank 1stD', 'Off. Rank Pen',\n",
    "             'Off. Rank Yds', 'Off. Rank 1stPy', 'Off. Rank #Dr', 'Def. Rank Ply', 'Def. Rank Y/P', 'Def. Rank Cmp',\n",
    "             'Def. Rank 1stD', 'Def. Rank 1stD', 'Def. Rank Pen', 'Def. Rank Yds', 'Def. Rank 1stPy', 'Def. Rank #Dr',\n",
    "             'Off. Rank 1stD.1', 'Off. Rank 1stD.2', 'Off. Rank Yds.3', 'Def. Rank 1stD.1', 'Def. Rank 1stD.2', 'Def. Rank Yds.3']\n",
    "UNIT_DICT = {'QB':'OFF','RB':'OFF','WR':'OFF','TE':'OFF',' C':'OFF',' G':'OFF',' T':'OFF','DT':'DEF','DE':'DEF','LB':'DEF',\n",
    "             'DB':'DEF'}\n",
    "NUM_NEIGHBORS = 10\n",
    "print(len(TEAM_DICT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WEB SCRAPING FUNCTIONS\n",
    "def get_first_rounders() -> list:\n",
    "    url = 'http://www.drafthistory.com/index.php/rounds/round_1'\n",
    "    response = get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    table = soup.find(id='main')\n",
    "    row_containers = table.table.find_all('tr')\n",
    "    row_containers = row_containers[2:]\n",
    "    labels = ['Year','Round','Pick','Player','Name','Team','Position','College']\n",
    "    \n",
    "    all_rows = []\n",
    "    should_break = False\n",
    "    for i in row_containers:\n",
    "        new_row = []\n",
    "        cols = i.find_all('td')\n",
    "        for j in range(0, len(cols)):\n",
    "            if j == 0:\n",
    "                try:\n",
    "                    year = int(cols[j].text)\n",
    "                    if year == CURRENT_YEAR - YEARS:\n",
    "                        should_break=True\n",
    "                        break\n",
    "                    new_row.append(cols[j].text)\n",
    "                except:\n",
    "                    new_row.append(year)\n",
    "            else:\n",
    "                new_row.append(cols[j].text)\n",
    "        if should_break:\n",
    "            break\n",
    "        if new_row:\n",
    "            all_rows.append(new_row)\n",
    "    \n",
    "    df = pd.DataFrame(all_rows,columns=labels)\n",
    "    df.drop(columns=['Round','Player','College'], inplace=True)\n",
    "    return df\n",
    "\n",
    "def get_team_stats_by_year_url(team_name: str, year) -> str:\n",
    "    base_url = 'https://www.pro-football-reference.com/teams/'\n",
    "    end_url = '.htm'\n",
    "    return base_url + TEAM_DICT[team_name] + '/' + str(year) + end_url\n",
    "\n",
    "def get_team_stats(url) -> 'DataFrame':\n",
    "    response = get(url)\n",
    "    if response.status_code == 404:\n",
    "        return pd.DataFrame()\n",
    "    soup = BeautifulSoup(response.text,'html.parser')\n",
    "    table_container = soup.find(id='all_team_stats')\n",
    "    if table_container:\n",
    "        print('Scraping', url)\n",
    "    else:\n",
    "        print(url)\n",
    "    table = table_container.find(class_='table_outer_container').div.table\n",
    "    \n",
    "    label_containers = table.thead.find_all('tr')[1].find_all('th')\n",
    "    labels = []\n",
    "    for i in label_containers:\n",
    "        labels.append(str(i.text))\n",
    "        \n",
    "    list_of_rows = []\n",
    "    row_containers = table.tbody.find_all('tr')\n",
    "    for i in row_containers:\n",
    "        row = []\n",
    "        row.append(i.th)\n",
    "        stat_containers = i.find_all('td')\n",
    "        for j in stat_containers:\n",
    "            try: \n",
    "                num = float(j.text)\n",
    "                row.append(num)\n",
    "            except:\n",
    "                row.append(str(j.text).strip())\n",
    "        list_of_rows.append(row)\n",
    "    \n",
    "    return pd.DataFrame(list_of_rows,columns=labels)\n",
    "\n",
    "def convert_team_stats_to_one_row(df) -> 'DataFrame':\n",
    "    team_columns = []\n",
    "    opp_columns = []\n",
    "    off_rank_columns = []\n",
    "    def_rank_columns = []\n",
    "    \n",
    "    for i in df.columns:\n",
    "        team_columns.append('Team ' + i)\n",
    "        opp_columns.append('Opp. ' + i)\n",
    "        off_rank_columns.append('Off. Rank ' + i)\n",
    "        def_rank_columns.append('Def. Rank ' + i)\n",
    "        \n",
    "    row1 = pd.DataFrame([list(df.loc[0])], columns=team_columns)\n",
    "    row2 = pd.DataFrame([list(df.loc[1])], columns=opp_columns)\n",
    "    row3 = pd.DataFrame([list(df.loc[2])], columns=off_rank_columns)\n",
    "    row4 = pd.DataFrame([list(df.loc[3])], columns=def_rank_columns)\n",
    "    \n",
    "    new_df = pd.concat([row1, row2, row3, row4], axis=1).reindex(row1.index)\n",
    "    return new_df\n",
    "\n",
    "def make_final_one_row(df, draft_year, pick_number, team_name, position_drafted) -> 'DataFrame':\n",
    "    df.drop(columns=['Team Player', 'Opp. Player', 'Off. Rank Player', 'Def. Rank Player'], inplace=True)\n",
    "    df.insert(0, 'Pick Number', [pick_number], True)\n",
    "    df.insert(0, 'Draft Year', [draft_year], True)\n",
    "    df.insert(0, 'Team', [team_name], True)\n",
    "    df.insert(0, 'Position Drafted', [position_drafted], True)\n",
    "    return df\n",
    "\n",
    "def get_final_df() -> 'DataFrame':\n",
    "    first_rounders = get_first_rounders()\n",
    "    frames = []\n",
    "    for i in first_rounders.index:\n",
    "        row = list(first_rounders.loc[i])\n",
    "\n",
    "        draft_year = row[0]\n",
    "        pick_number = row[1]\n",
    "        team_name = row[3]\n",
    "        position_drafted = row[4]\n",
    "\n",
    "        stats_url = get_team_stats_by_year_url(team_name, int(draft_year)-1)\n",
    "        team_stats_df = get_team_stats(stats_url)\n",
    "        if team_stats_df.empty:\n",
    "            print('Not Found', stats_url)\n",
    "            continue\n",
    "        else:\n",
    "            pass\n",
    "        one_row = convert_team_stats_to_one_row(team_stats_df)\n",
    "        final_row = make_final_one_row(one_row, draft_year, pick_number, team_name, position_drafted)\n",
    "        frames.append(final_row)\n",
    "    final_df = pd.concat(frames)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = get_final_df()\n",
    "final_df.to_csv('Profile For Last ' + str(YEARS) + ' Drafts.csv', encoding = 'utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Profile For Last 20 Drafts.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-dc5118e1bbc7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfinal_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Profile For Last '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mYEARS\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' Drafts.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfinal_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1872\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1873\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1874\u001b[1;33m                 \u001b[0msrc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1875\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1876\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Profile For Last 20 Drafts.csv'"
     ]
    }
   ],
   "source": [
    "final_df = pd.read_csv('Profile For Last ' + str(YEARS) + ' Drafts.csv', encoding = 'utf-8')\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_final_df(final_df) -> 'DataFrame':\n",
    "    \n",
    "    team_start_list = []\n",
    "    opp_start_list = []\n",
    "    for i in list(final_df['Team Start']):\n",
    "        team_start_list.append(float(str(i)[4:].strip()))\n",
    "    for i in list(final_df['Opp. Start']):\n",
    "        opp_start_list.append(float(str(i)[4:].strip()))\n",
    "    \n",
    "    final_df['Team Start'] = team_start_list\n",
    "    final_df['Opp. Start'] = opp_start_list\n",
    "    \n",
    "    team_time_list = []\n",
    "    opp_time_list = []\n",
    "    for i in list(final_df['Team Time']):\n",
    "        team_time_list.append(float((int(str(i)[0])*60)+int(str(i)[2:])))\n",
    "    for i in list(final_df['Opp. Time']):\n",
    "        opp_time_list.append(float((int(str(i)[0])*60)+int(str(i)[2:])))\n",
    "        \n",
    "    final_df['Team Time'] = team_time_list\n",
    "    final_df['Opp. Time'] = opp_time_list\n",
    "    \n",
    "    for i in final_df:\n",
    "        if i in EMPTY_COLS:\n",
    "            final_df = final_df.drop(columns=i)\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_final_df = clean_final_df(final_df)\n",
    "reference_df = clean_final_df.copy(deep=True)\n",
    "clean_final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_final_df_to_num(final_df) -> 'DataFrame':\n",
    "    years_list = []\n",
    "    for i in list(final_df['Draft Year']):\n",
    "        years_list.append(int(i))\n",
    "    final_df.index = years_list\n",
    "    \n",
    "    # num_df = final_df.drop(columns=['Position Drafted','Team','Draft Year'])\n",
    "    num_df['Position Drafted'] = num_df['Position Drafted'].map(POS_DICT)\n",
    "    return num_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df = convert_final_df_to_num(clean_final_df)\n",
    "num_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dfs(final_df) -> list:\n",
    "\n",
    "    train_df_years = [*range(CURRENT_YEAR-1, CURRENT_YEAR - YEARS, -1)]\n",
    "\n",
    "    test_df = final_df.loc[[CURRENT_YEAR]]\n",
    "    train_df = final_df.loc[train_df_years]\n",
    "    print(train_df.shape, test_df.shape)\n",
    "\n",
    "    combine = [train_df, test_df]\n",
    "    return combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine = split_dfs(num_df)\n",
    "train_df = combine[0]\n",
    "test_df = combine[1]\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "train_df.head()\n",
    "\n",
    "# test_df.to_csv('Test_DF.csv', encoding='utf-8-sig', index=True)\n",
    "# train_df.to_csv('Train_DF.csv', encoding = 'utf-8-sig', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.index = train_df.index + 32\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PREPARATION FUNCTIONS\n",
    "\n",
    "def convert_df_to_weighted_df(df):\n",
    "    std_list = list(df.std(axis = 0, skipna= True))\n",
    "    mean_list = list(df.mean(axis=0, skipna= True))\n",
    "    frames = []\n",
    "    for i in range(df.index[0], df.index[0]+len(df.index)):\n",
    "        row_list = list(df.loc[i])\n",
    "        weighted_row = []\n",
    "        for j in range(len(row_list)):\n",
    "            weighted_row.append((row_list[j] - mean_list[j])/std_list[j])\n",
    "        weighted_df_row = pd.DataFrame([weighted_row], columns=df.columns)\n",
    "        frames.append(weighted_df_row)\n",
    "    weighted_df = pd.concat(frames)\n",
    "    weighted_df.index = df.index\n",
    "    return weighted_df\n",
    "\n",
    "def ready_dataset_for_modeling(train_df, test_df) -> list:\n",
    "    weighted_train_df = convert_df_to_weighted_df(train_df)\n",
    "    weighted_test_df = convert_df_to_weighted_df(test_df)\n",
    "    \n",
    "    train_dataset = weighted_train_df.to_numpy().tolist()\n",
    "    test_dataset = weighted_test_df.to_numpy().tolist()\n",
    "    \n",
    "    combine = [train_dataset, test_dataset]\n",
    "    return combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ready_combine = ready_dataset_for_modeling(train_df, test_df)\n",
    "train_dataset = model_ready_combine[0]\n",
    "test_dataset = model_ready_combine[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K NEAREST NEIGHBORS MODEL FUNCTIONS\n",
    "\n",
    "def euclidean_distance(row1, row2):\n",
    "    distance = 0.0\n",
    "    for i in range(len(row1)-1):\n",
    "        distance += (row1[i] - row2[i])**2\n",
    "    return math.sqrt(distance)\n",
    "\n",
    "def get_neighbors(train, test_row, num_neighbors):\n",
    "    distances = list()\n",
    "    for i in range(0, len(train)-1):\n",
    "        index = i+32\n",
    "        train_row = train[i]\n",
    "        dist = euclidean_distance(test_row, train_row)\n",
    "        distances.append((train_row, dist, index))\n",
    "    distances.sort(key=lambda tup: tup[1])\n",
    "    neighbors = list()\n",
    "    for i in range(num_neighbors):\n",
    "        neighbors.append((distances[i][2], round(distances[i][1], 2)))\n",
    "    return neighbors\n",
    "\n",
    "def prediction_data(test_row_index) -> 'DataFrame':\n",
    "    neighbors = get_neighbors(train_dataset, test_dataset[test_row_index], NUM_NEIGHBORS)\n",
    "    \n",
    "    frames = []\n",
    "    index_col = [test_row_index]\n",
    "    distance_col = [0]\n",
    "    \n",
    "    for neighbor in neighbors:\n",
    "        index_col.append(neighbor[0])\n",
    "        distance_col.append(neighbor[1])\n",
    "        frames.append(pd.DataFrame([list(reference_df.loc[int(neighbor[0])])], columns=reference_df.columns))\n",
    "        \n",
    "    big_df = pd.concat(frames)\n",
    "    big_df = pd.DataFrame([reference_df.loc[test_row_index]], columns=reference_df.columns).append(big_df, ignore_index=True)\n",
    "    big_df.insert(0, 'Distance', distance_col, True)\n",
    "    big_df.insert(0, 'Index', index_col, True)\n",
    "    big_df.insert(2, 'Unit', big_df['Position Drafted'].map(UNIT_DICT), True)\n",
    "    \n",
    "    return big_df\n",
    "\n",
    "def unit_prediction(test_row_index):\n",
    "    predict_dict = {}\n",
    "    neighbors = get_neighbors(train_dataset, test_dataset[test_row_index], NUM_NEIGHBORS)\n",
    "    \n",
    "    sum = 0\n",
    "    for neighbor in neighbors:\n",
    "        position = list(reference_df.loc[int(neighbor[0])])[0]\n",
    "        for i in UNIT_DICT.keys():\n",
    "            if position == i:\n",
    "                unit = UNIT_DICT[position]\n",
    "        if unit not in predict_dict:\n",
    "            predict_dict[unit] = 0\n",
    "        predict_dict[unit] += 1\n",
    "        sum += 1\n",
    "        \n",
    "    #print('Actual Unit: ' + UNIT_DICT[list(reference_df.loc[test_row_index])[0]])\n",
    "    #for i in predict_dict:\n",
    "        #print(i, 'Count:'+str(predict_dict[i]), str(round(predict_dict[i]/sum, 4)*100) + '%')\n",
    "    \n",
    "    percent_dict = {}\n",
    "    for i in predict_dict:\n",
    "        percent_dict[i] = round(predict_dict[i]/sum, 4)*100\n",
    "    percent_dict['Actual Unit'] = UNIT_DICT[list(reference_df.loc[test_row_index])[0]]\n",
    "    return percent_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PICK_NUM = 1\n",
    "test = prediction_data(PICK_NUM-1)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_prediction(PICK_NUM-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING\n",
    "\n",
    "def test_unit_prediction():\n",
    "    correct_predictions = 0\n",
    "    length = len(test_df.index)\n",
    "    for i in range(length):\n",
    "        predict_dict = unit_prediction(i)\n",
    "        offense = predict_dict['OFF']\n",
    "        defense = predict_dict['DEF']\n",
    "        if predict_dict['Actual Unit'] == 'OFF' and offense > defense:\n",
    "            correct_predictions += 1\n",
    "        elif predict_dict['Actual Unit'] == 'DEF' and defense > offense:\n",
    "            correct_predictions += 1\n",
    "    return round(correct_predictions/length, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_unit_prediction()\n",
    "# All Columns Accuracy: .5312\n",
    "# No Rank Columns Accuracy: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
